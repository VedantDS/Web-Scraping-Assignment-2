{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Q1: Write a  program to scrape data for “Data Analyst” Job position in“Bangalore” location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining function\n",
    "def jobs_data_ana_sci(job_position, webdriver_path):\n",
    "    # initializing web driver and webpage\n",
    "    driver  = webdriver.Chrome(webdriver_path)\n",
    "    driver.get('https://www.naukri.com/')\n",
    "    # search job position and location\n",
    "    driver.find_element_by_id('qsb-keyword-sugg').send_keys(job_position)\n",
    "    driver.find_element_by_id('qsb-location-sugg').send_keys('Bangalore')\n",
    "    driver.find_element_by_class_name('search-btn').click()\n",
    "    time.sleep(3)\n",
    "\n",
    "    # extracting 'job_title', 'company', 'location','experience' and salary for first 10 jobs\n",
    "    bs= BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    job_info = bs.find_all('div', attrs ={'class':'jobTupleHeader'})[:10]\n",
    "    job_title = [j.text for i in job_info for j in i.find_all('a','title fw500 ellipsis')]\n",
    "    company = [j.text for i in job_info for j in i.find_all('a','subTitle ellipsis fleft')]\n",
    "    location = [j.text for i in job_info for j in i.find_all('li','fleft grey-text br2 placeHolderLi location')]\n",
    "    experience = [j.text for i in job_info for j in i.find_all('li','fleft grey-text br2 placeHolderLi experience')]\n",
    "    salary = [j.find('span','ellipsis fleft fs12 lh16').get_text() for i in job_info for j in i.find_all('li','fleft grey-text br2 placeHolderLi salary')]\n",
    "\n",
    "    # extracting job page url for each job\n",
    "    jobs_url = bs.find_all('a', attrs ={'class':'title fw500 ellipsis'})\n",
    "    \n",
    "    # extracting job description correspounding to each job url.\n",
    "    job_decr = []\n",
    "    for i in jobs_url[:10]:\n",
    "                driver.get(i['href'])\n",
    "                bs= BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                try:\n",
    "                    job_decr.append(bs.find('section','job-desc').text)\n",
    "                except AttributeError:\n",
    "                    try:\n",
    "                        job_decr.append(bs.find('section','JD av_textblock_section').text.replace('\\n',' '))\n",
    "                    except AttributeError:\n",
    "                        try:\n",
    "                            job_decr.append(bs.find('div','ptb20 hLine').text.replace('\\n',' '))\n",
    "                        except:\n",
    "                            job_decr.append('-')\n",
    "\n",
    "\n",
    "    job_df = pd.DataFrame({'Job_title':job_title,\n",
    "                                  'Company':company,\n",
    "                                  'Location': location,\n",
    "                                  'Experience':experience,\n",
    "                                  'Salary': salary,\n",
    "                                  'Job_description':job_decr \n",
    "                          })\n",
    "    return job_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fresher  Data Engineer / Data Scientist / Data...</td>\n",
       "      <td>ACHYUTAS SOFT PRIVATE LIMITED</td>\n",
       "      <td>Delhi NCR, Bengaluru, Hyderabad</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>3,50,000 - 8,50,000 PA.</td>\n",
       "      <td>Job descriptionRoles and ResponsibilitiesAnaly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist/Data Analyst</td>\n",
       "      <td>CAIA-Center For Artificial Intelligence &amp; Adva...</td>\n",
       "      <td>Chennai, Pune, Bengaluru, Hyderabad</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>3,50,000 - 4,50,000 PA.</td>\n",
       "      <td>Job description Dear Candidate  Schedule a Tel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>NetApp</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2-3 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Job Description   Job Summary:    Data Analys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SAS AML Data Analyst / Trainee &amp; Data Science,...</td>\n",
       "      <td>MagicBase Royal BD Pvt Ltd</td>\n",
       "      <td>Bengaluru(Whitefield)</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>50,000 - 2,00,000 PA.</td>\n",
       "      <td>Job descriptionWe are looking to hire SAS Anal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hiring Data Analysts</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>3,00,000 - 6,00,000 PA.</td>\n",
       "      <td>Job description Hiring Data Analyst profile on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hiring Data Analysts</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>2,50,000 - 5,50,000 PA.</td>\n",
       "      <td>Job description Flipkart is looking for Data A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>Bengaluru, India</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Job Description    Roles and ResponsibilitiesS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Study Data Analyst</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Job Description    Roles and ResponsibilitiesA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Cognizant Technology Solutions India Ltd</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>3-4 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Job Description    Roles and ResponsibilitiesT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Business Data Analyst | Reinsurance Domain</td>\n",
       "      <td>Mphasis Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>10-15 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Job Description    Roles and ResponsibilitiesR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0  Fresher  Data Engineer / Data Scientist / Data...   \n",
       "1                        Data Scientist/Data Analyst   \n",
       "2                              Business Data Analyst   \n",
       "3  SAS AML Data Analyst / Trainee & Data Science,...   \n",
       "4                               Hiring Data Analysts   \n",
       "5                               Hiring Data Analysts   \n",
       "6                                       Data Analyst   \n",
       "7                                 Study Data Analyst   \n",
       "8                                       Data Analyst   \n",
       "9         Business Data Analyst | Reinsurance Domain   \n",
       "\n",
       "                                             Company  \\\n",
       "0                     ACHYUTAS SOFT PRIVATE LIMITED    \n",
       "1  CAIA-Center For Artificial Intelligence & Adva...   \n",
       "2                                             NetApp   \n",
       "3                         MagicBase Royal BD Pvt Ltd   \n",
       "4                  Flipkart Internet Private Limited   \n",
       "5                  Flipkart Internet Private Limited   \n",
       "6            GlaxoSmithKline Pharmaceuticals Limited   \n",
       "7            GlaxoSmithKline Pharmaceuticals Limited   \n",
       "8           Cognizant Technology Solutions India Ltd   \n",
       "9                                    Mphasis Limited   \n",
       "\n",
       "                              Location Experience                   Salary  \\\n",
       "0      Delhi NCR, Bengaluru, Hyderabad    0-2 Yrs  3,50,000 - 8,50,000 PA.   \n",
       "1  Chennai, Pune, Bengaluru, Hyderabad    0-3 Yrs  3,50,000 - 4,50,000 PA.   \n",
       "2                            Bengaluru    2-3 Yrs            Not disclosed   \n",
       "3                Bengaluru(Whitefield)    0-5 Yrs    50,000 - 2,00,000 PA.   \n",
       "4                            Bengaluru    2-5 Yrs  3,00,000 - 6,00,000 PA.   \n",
       "5                            Bengaluru    2-5 Yrs  2,50,000 - 5,50,000 PA.   \n",
       "6                     Bengaluru, India    3-5 Yrs            Not disclosed   \n",
       "7                            Bengaluru    4-8 Yrs            Not disclosed   \n",
       "8                            Bengaluru    3-4 Yrs            Not disclosed   \n",
       "9                            Bengaluru  10-15 Yrs            Not disclosed   \n",
       "\n",
       "                                     Job_description  \n",
       "0  Job descriptionRoles and ResponsibilitiesAnaly...  \n",
       "1  Job description Dear Candidate  Schedule a Tel...  \n",
       "2   Job Description   Job Summary:    Data Analys...  \n",
       "3  Job descriptionWe are looking to hire SAS Anal...  \n",
       "4  Job description Hiring Data Analyst profile on...  \n",
       "5  Job description Flipkart is looking for Data A...  \n",
       "6  Job Description    Roles and ResponsibilitiesS...  \n",
       "7  Job Description    Roles and ResponsibilitiesA...  \n",
       "8  Job Description    Roles and ResponsibilitiesT...  \n",
       "9  Job Description    Roles and ResponsibilitiesR...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calling function 'jobs_data_ana_sci' for scraping 'Data Analyst' jobs data at 'Bangalore'\n",
    "jobs_data_ana_sci(job_position = 'Data Analyst', webdriver_path = r'C:\\Users\\91743\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2: Write a  program to scrape data for “Data Scientist” Job position in “Bangalore” location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fresher  Data Engineer / Data Scientist / Data...</td>\n",
       "      <td>ACHYUTAS SOFT PRIVATE LIMITED</td>\n",
       "      <td>Delhi NCR, Bengaluru, Hyderabad</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>3,50,000 - 8,50,000 PA.</td>\n",
       "      <td>Job descriptionRoles and ResponsibilitiesAnaly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist/Data Analyst</td>\n",
       "      <td>CAIA-Center For Artificial Intelligence &amp; Adva...</td>\n",
       "      <td>Chennai, Pune, Bengaluru, Hyderabad</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>3,50,000 - 4,50,000 PA.</td>\n",
       "      <td>Job description Dear Candidate  Schedule a Tel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Machine Learning/Data Mining</td>\n",
       "      <td>Minions Ventures</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Job descriptionKey Responsibilities :- Use ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>BLUE YONDER INDIA PRIVATE LIMITED</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Job Description    The Yantriks Data Science a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist - NLP/ Python/ R</td>\n",
       "      <td>AVI Consulting LLP</td>\n",
       "      <td>Bengaluru, Hyderabad</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Job descriptionRoles and ResponsibilitiesSkill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "      <td>CES Ltd.</td>\n",
       "      <td>Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>7,00,000 - 15,00,000 PA.</td>\n",
       "      <td>Job descriptionRoles and Responsibilities  Mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "      <td>CES Ltd.</td>\n",
       "      <td>Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>7,00,000 - 15,00,000 PA.</td>\n",
       "      <td>Job descriptionRoles and Responsibilities  Mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Python/MATLAB/Machine Learnin...</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Job descriptionRoles and ResponsibilitiesData ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lead Data Scientist - Machine Learning/Data Mi...</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Job descriptionRoles and ResponsibilitiesRequi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist  -  Machine Learning -  Remote ...</td>\n",
       "      <td>Doji Ltd</td>\n",
       "      <td>Delhi NCR, Bengaluru, Anywhere in India</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>15,00,000 - 20,00,000 PA.</td>\n",
       "      <td>Job descriptionPlease note that this role will...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0  Fresher  Data Engineer / Data Scientist / Data...   \n",
       "1                        Data Scientist/Data Analyst   \n",
       "2      Data Scientist - Machine Learning/Data Mining   \n",
       "3                  Data Scientist - Machine Learning   \n",
       "4             Senior Data Scientist - NLP/ Python/ R   \n",
       "5  Senior Data Scientist | CES IT LTD | CMMI Level 5   \n",
       "6  Senior Data Scientist | CES IT LTD | CMMI Level 5   \n",
       "7  Data Scientist - Python/MATLAB/Machine Learnin...   \n",
       "8  Lead Data Scientist - Machine Learning/Data Mi...   \n",
       "9  Data Scientist  -  Machine Learning -  Remote ...   \n",
       "\n",
       "                                             Company  \\\n",
       "0                     ACHYUTAS SOFT PRIVATE LIMITED    \n",
       "1  CAIA-Center For Artificial Intelligence & Adva...   \n",
       "2                                   Minions Ventures   \n",
       "3                  BLUE YONDER INDIA PRIVATE LIMITED   \n",
       "4                                 AVI Consulting LLP   \n",
       "5                                           CES Ltd.   \n",
       "6                                           CES Ltd.   \n",
       "7                       Wrackle Technologies Pvt Ltd   \n",
       "8                       Wrackle Technologies Pvt Ltd   \n",
       "9                                           Doji Ltd   \n",
       "\n",
       "                                            Location Experience  \\\n",
       "0                    Delhi NCR, Bengaluru, Hyderabad    0-2 Yrs   \n",
       "1                Chennai, Pune, Bengaluru, Hyderabad    0-3 Yrs   \n",
       "2                                          Bengaluru    6-8 Yrs   \n",
       "3                                          Bengaluru    2-7 Yrs   \n",
       "4                               Bengaluru, Hyderabad    4-9 Yrs   \n",
       "5  Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...    2-7 Yrs   \n",
       "6  Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...    2-7 Yrs   \n",
       "7                                          Bengaluru    3-8 Yrs   \n",
       "8                                          Bengaluru   6-11 Yrs   \n",
       "9            Delhi NCR, Bengaluru, Anywhere in India    2-5 Yrs   \n",
       "\n",
       "                      Salary  \\\n",
       "0    3,50,000 - 8,50,000 PA.   \n",
       "1    3,50,000 - 4,50,000 PA.   \n",
       "2              Not disclosed   \n",
       "3              Not disclosed   \n",
       "4              Not disclosed   \n",
       "5   7,00,000 - 15,00,000 PA.   \n",
       "6   7,00,000 - 15,00,000 PA.   \n",
       "7              Not disclosed   \n",
       "8              Not disclosed   \n",
       "9  15,00,000 - 20,00,000 PA.   \n",
       "\n",
       "                                     Job_description  \n",
       "0  Job descriptionRoles and ResponsibilitiesAnaly...  \n",
       "1  Job description Dear Candidate  Schedule a Tel...  \n",
       "2  Job descriptionKey Responsibilities :- Use ana...  \n",
       "3  Job Description    The Yantriks Data Science a...  \n",
       "4  Job descriptionRoles and ResponsibilitiesSkill...  \n",
       "5  Job descriptionRoles and Responsibilities  Mus...  \n",
       "6  Job descriptionRoles and Responsibilities  Mus...  \n",
       "7  Job descriptionRoles and ResponsibilitiesData ...  \n",
       "8  Job descriptionRoles and ResponsibilitiesRequi...  \n",
       "9  Job descriptionPlease note that this role will...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calling function 'jobs_data_ana_sci' for scraping 'Data Scientist' jobs data at 'Bangalore'\n",
    "jobs_data_ana_sci(job_position = 'Data Scientist', webdriver_path = r'C:\\Users\\91743\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3: Write a program to scrape job data using the filters 'Location' and 'Salary'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fresher  Data Engineer / Data Scientist / Data...</td>\n",
       "      <td>ACHYUTAS SOFT PRIVATE LIMITED</td>\n",
       "      <td>Delhi NCR, Bengaluru, Hyderabad</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GCP Skilled Analytics Resources (Data engineer...</td>\n",
       "      <td>Aerial Telecom Solutions Pvt. Ltd.</td>\n",
       "      <td>Pune, Bengaluru, Gurgaon</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GCP Skilled Analytics Resources (Data engineer...</td>\n",
       "      <td>Aerial Telecom Solutions Pvt. Ltd.</td>\n",
       "      <td>Pune, Bengaluru, Gurgaon</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Python/Machine Learning</td>\n",
       "      <td>Jubna</td>\n",
       "      <td>Noida</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>PureSoftware Pvt Ltd.</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>World Wide Technology</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LTD</td>\n",
       "      <td>Delhi NCR, Noida(Sector-142 Noida)</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Excellent opportunity For Lead Data Scientist ...</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LTD</td>\n",
       "      <td>Delhi NCR(Sector-142 Noida), Noida</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LTD</td>\n",
       "      <td>Delhi NCR, Noida(Sector-142 Noida)</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Excellent opportunity For Lead Data Scientist ...</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LTD</td>\n",
       "      <td>Delhi NCR(Sector-142 Noida), Noida</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0  Fresher  Data Engineer / Data Scientist / Data...   \n",
       "1  GCP Skilled Analytics Resources (Data engineer...   \n",
       "2  GCP Skilled Analytics Resources (Data engineer...   \n",
       "3           Data Scientist - Python/Machine Learning   \n",
       "4                                     Data Scientist   \n",
       "5                                     Data Scientist   \n",
       "6                                Lead Data Scientist   \n",
       "7  Excellent opportunity For Lead Data Scientist ...   \n",
       "8                                Lead Data Scientist   \n",
       "9  Excellent opportunity For Lead Data Scientist ...   \n",
       "\n",
       "                              Company                            Location  \\\n",
       "0      ACHYUTAS SOFT PRIVATE LIMITED      Delhi NCR, Bengaluru, Hyderabad   \n",
       "1  Aerial Telecom Solutions Pvt. Ltd.            Pune, Bengaluru, Gurgaon   \n",
       "2  Aerial Telecom Solutions Pvt. Ltd.            Pune, Bengaluru, Gurgaon   \n",
       "3                               Jubna                               Noida   \n",
       "4               PureSoftware Pvt Ltd.                             Gurgaon   \n",
       "5               World Wide Technology                             Gurgaon   \n",
       "6   NEC CORPORATION INDIA PRIVATE LTD  Delhi NCR, Noida(Sector-142 Noida)   \n",
       "7   NEC CORPORATION INDIA PRIVATE LTD  Delhi NCR(Sector-142 Noida), Noida   \n",
       "8   NEC CORPORATION INDIA PRIVATE LTD  Delhi NCR, Noida(Sector-142 Noida)   \n",
       "9   NEC CORPORATION INDIA PRIVATE LTD  Delhi NCR(Sector-142 Noida), Noida   \n",
       "\n",
       "  Experience  \n",
       "0    0-2 Yrs  \n",
       "1    3-8 Yrs  \n",
       "2    3-8 Yrs  \n",
       "3    5-8 Yrs  \n",
       "4    5-9 Yrs  \n",
       "5    3-8 Yrs  \n",
       "6   9-14 Yrs  \n",
       "7   9-14 Yrs  \n",
       "8   9-14 Yrs  \n",
       "9   9-14 Yrs  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing web driver and webpage\n",
    "driver  = webdriver.Chrome( r'C:\\Users\\91743\\chromedriver.exe')\n",
    "driver.get('https://www.naukri.com/')\n",
    " # search job position\n",
    "driver.find_element_by_id('qsb-keyword-sugg').send_keys('Data Scientist')\n",
    "driver.find_element_by_class_name('search-btn').click()\n",
    "time.sleep(3)\n",
    "# check location as 'Delhi/NCR' and salary as '3-6 lakhs'\n",
    "driver.find_element_by_xpath('//label[@class=\"chkLbl\" and @for = \"chk-Delhi/NCR-cityType-\"]/i').click()\n",
    "time.sleep(3)\n",
    "driver.find_element_by_xpath('//label[@class=\"chkLbl\" and @for = \"chk-3-6 Lakhs-ctcFilter-\"]/i').click()\n",
    "time.sleep(3)\n",
    "\n",
    "# extracting 'job_title', 'company', 'location' and 'experience' for first 10 jobs\n",
    "bs= BeautifulSoup(driver.page_source, 'html.parser')\n",
    "jobs = bs.find_all('div', attrs ={'class':'jobTupleHeader'})[:10]\n",
    "job_title = [j.text for i in jobs for j in i.find_all('a','title fw500 ellipsis')]\n",
    "company = [j.text for i in jobs for j in i.find_all('a','subTitle ellipsis fleft')]\n",
    "location = [j.get_text() for i in jobs for j in i.find_all('li','fleft grey-text br2 placeHolderLi location')]\n",
    "experience = [j.get_text() for i in jobs for j in i.find_all('li','fleft grey-text br2 placeHolderLi experience')]\n",
    "\n",
    "job_df = pd.DataFrame({'Job_title':job_title,\n",
    "                       'Company':company,\n",
    "                       'Location': location,\n",
    "                       'Experience':experience,\n",
    "                      })\n",
    "job_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4: Write a  program to scrape data for first 10 job results for Data scientist Designation in Noida location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Days_ago</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Genpact</td>\n",
       "      <td>1d</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IHS Markit</td>\n",
       "      <td>8d</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gauge Data Solutions</td>\n",
       "      <td>24h</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GroundTruth</td>\n",
       "      <td>21d</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Algoscale</td>\n",
       "      <td>24h</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MARKTECH CONSULTANCY</td>\n",
       "      <td>6d</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Techlive</td>\n",
       "      <td>6d</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SearchUrCollege</td>\n",
       "      <td>24h</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Priority Vendor</td>\n",
       "      <td>24h</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Healtheoz India</td>\n",
       "      <td>24h</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company Days_ago Rating\n",
       "0               Genpact       1d    3.8\n",
       "1            IHS Markit       8d    4.1\n",
       "2  Gauge Data Solutions      24h    3.1\n",
       "3           GroundTruth      21d    3.3\n",
       "4             Algoscale      24h    3.7\n",
       "5  MARKTECH CONSULTANCY       6d      -\n",
       "6              Techlive       6d      5\n",
       "7       SearchUrCollege      24h      -\n",
       "8       Priority Vendor      24h      4\n",
       "9       Healtheoz India      24h    4.8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing web driver and webpage\n",
    "driver  = webdriver.Chrome( r'C:\\Users\\91743\\chromedriver.exe')\n",
    "driver.get('https://www.glassdoor.co.in/Job/index.htm')\n",
    "# search job position and location\n",
    "driver.find_element_by_id('KeywordSearch').send_keys('Data Scientist')\n",
    "driver.find_element_by_id('LocationSearch').clear()\n",
    "driver.find_element_by_id('LocationSearch').send_keys('Noida')\n",
    "driver.find_element_by_class_name('gd-btn-mkt').click()\n",
    "time.sleep(3)\n",
    "\n",
    "# extracting  'company', 'no. of days ago' and 'rating' for first 10 jobs\n",
    "bs= BeautifulSoup(driver.page_source, 'html.parser')\n",
    "jobs = bs.find_all('ul', attrs ={'class':'jlGrid hover p-0'})\n",
    "company = [j.text for i in jobs for j in i.find_all('a','css-10l5u4p e1n63ojh0 jobLink')[:10]]\n",
    "ndays_ago = [j.text for i in jobs for j in i.find_all('div','d-flex align-items-end pl-std css-mi55ob')[:10]]\n",
    "\n",
    "ratings = []\n",
    "for i in jobs:\n",
    "       for j in i.find_all('div','d-flex flex-column css-fbt9gv e1rrn5ka2')[:10]:\n",
    "            if j.text != '':\n",
    "                ratings.append(j.text)\n",
    "            else:\n",
    "                ratings.append('-')\n",
    "                \n",
    "    \n",
    "job_df = pd.DataFrame({'Company': company,\n",
    "                       'Days_ago': ndays_ago,\n",
    "                       'Rating': ratings})\n",
    "job_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5: Write a program to scrape the salary data for Data Scientist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Mininum_salary</th>\n",
       "      <th>Maximum_salary</th>\n",
       "      <th>Average_salary</th>\n",
       "      <th>No. of salaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>₹705K</td>\n",
       "      <td>₹11,495K</td>\n",
       "      <td>₹ 12,83,026</td>\n",
       "      <td>12 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>₹571K</td>\n",
       "      <td>₹2,200K</td>\n",
       "      <td>₹ 11,19,272</td>\n",
       "      <td>9 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IBM</td>\n",
       "      <td>₹580K</td>\n",
       "      <td>₹2,700K</td>\n",
       "      <td>₹ 7,52,445</td>\n",
       "      <td>7 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>₹468K</td>\n",
       "      <td>₹1,595K</td>\n",
       "      <td>₹ 8,28,000</td>\n",
       "      <td>7 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>₹708K</td>\n",
       "      <td>₹1,557K</td>\n",
       "      <td>₹ 13,21,601</td>\n",
       "      <td>7 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Analytics Vidhya</td>\n",
       "      <td>₹14K</td>\n",
       "      <td>₹22K</td>\n",
       "      <td>₹ 20,889</td>\n",
       "      <td>7 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>₹488K</td>\n",
       "      <td>₹1,000K</td>\n",
       "      <td>₹ 6,33,432</td>\n",
       "      <td>6 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cognizant Technology Solutions</td>\n",
       "      <td>₹784K</td>\n",
       "      <td>₹1,250K</td>\n",
       "      <td>₹ 9,96,446</td>\n",
       "      <td>6 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>₹496K</td>\n",
       "      <td>₹1,138K</td>\n",
       "      <td>₹ 7,71,320</td>\n",
       "      <td>6 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vidooly Media Tech</td>\n",
       "      <td>₹8K</td>\n",
       "      <td>₹20K</td>\n",
       "      <td>₹ 12,669</td>\n",
       "      <td>6 salaries</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Company Mininum_salary Maximum_salary  \\\n",
       "0                       Delhivery          ₹705K       ₹11,495K   \n",
       "1                       Accenture          ₹571K        ₹2,200K   \n",
       "2                             IBM          ₹580K        ₹2,700K   \n",
       "3              Ericsson-Worldwide          ₹468K        ₹1,595K   \n",
       "4              UnitedHealth Group          ₹708K        ₹1,557K   \n",
       "5                Analytics Vidhya           ₹14K           ₹22K   \n",
       "6       Tata Consultancy Services          ₹488K        ₹1,000K   \n",
       "7  Cognizant Technology Solutions          ₹784K        ₹1,250K   \n",
       "8              Valiance Solutions          ₹496K        ₹1,138K   \n",
       "9              Vidooly Media Tech            ₹8K           ₹20K   \n",
       "\n",
       "  Average_salary No. of salaries  \n",
       "0    ₹ 12,83,026     12 salaries  \n",
       "1    ₹ 11,19,272      9 salaries  \n",
       "2     ₹ 7,52,445      7 salaries  \n",
       "3     ₹ 8,28,000      7 salaries  \n",
       "4    ₹ 13,21,601      7 salaries  \n",
       "5       ₹ 20,889      7 salaries  \n",
       "6     ₹ 6,33,432      6 salaries  \n",
       "7     ₹ 9,96,446      6 salaries  \n",
       "8     ₹ 7,71,320      6 salaries  \n",
       "9       ₹ 12,669      6 salaries  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing web driver and webpage\n",
    "driver  = webdriver.Chrome( r'C:\\Users\\91743\\chromedriver.exe')\n",
    "driver.get('https://www.glassdoor.co.in/Salaries/index.htm')\n",
    "# search job position and location\n",
    "driver.find_element_by_id('KeywordSearch').send_keys('Data Scientist')\n",
    "driver.find_element_by_id('LocationSearch').clear()\n",
    "driver.find_element_by_id('LocationSearch').send_keys('Noida')\n",
    "driver.find_element_by_class_name('gd-btn-mkt').click()\n",
    "time.sleep(3)\n",
    "\n",
    "# extracting 'company', 'average salary','minimum salary','maximum salary' and 'no. of salaries' for first 10 jobs\n",
    "bs= BeautifulSoup(driver.page_source, 'html.parser')\n",
    "company = [i.text for i in driver.find_elements_by_xpath('//div[@class = \"d-flex\"]/div[2]/p[2]')[:10]]\n",
    "avg_sal = [i.text for i in driver.find_elements_by_xpath('//div[@class=\"col-2 d-none d-md-flex flex-row justify-content-end\"]/strong')[:10]]\n",
    "min_sal = [i.text for i in driver.find_elements_by_xpath('//div[@class= \"col-3 offset-1 d-none d-md-block\" ]/div/div[2]/span[1]')[:10]]\n",
    "max_sal = [i.text for i in driver.find_elements_by_xpath('//div[@class= \"col-3 offset-1 d-none d-md-block\" ]/div/div[2]/span[2]')[:10]]\n",
    "n_sal = [i.text for i in driver.find_elements_by_xpath('//p[@class= \"css-1uyte9r css-1kuy7z7 m-0\" ]')[:10]]\n",
    "\n",
    "job_sal_df = pd.DataFrame({'Company': company,\n",
    "                       'Mininum_salary': min_sal,\n",
    "                       'Maximum_salary': max_sal,\n",
    "                       'Average_salary': avg_sal,\n",
    "                       'No. of salaries':n_sal})\n",
    "job_sal_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q6 : Program to  scrape data of  sunglasses listings on flipkart.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining function\n",
    "def flipkart_products(product):\n",
    "    # initializing web driver and webpage\n",
    "    driver  = webdriver.Chrome( r'C:\\Users\\91743\\chromedriver.exe')\n",
    "    driver.get('https://www.flipkart.com/')\n",
    "    print('loading.............','\\n')\n",
    "    time.sleep(3)\n",
    "    driver.find_element_by_xpath('/html/body/div[2]/div/div/button').click() # closing pop ups\n",
    "    # seach for given product\n",
    "    driver.find_element_by_class_name('_3704LK').send_keys(product)\n",
    "    driver.find_element_by_class_name('L0Z3Pu').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # loop to scape all product related data for each page till page 3\n",
    "    brand = []\n",
    "    product = []\n",
    "    price = []\n",
    "    discount = []\n",
    "    page = 1\n",
    "    end_page = 3\n",
    "    nxt = driver.find_element_by_class_name('_1LKTO3')\n",
    "    while page <= end_page:\n",
    "        bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        item_info = bs.find_all('div', attrs ={'class':'E2-pcE _1q8tSL'})\n",
    "        for i in item_info:\n",
    "\n",
    "            for j in i.find_all('div','_2WkVRV'):\n",
    "                brand.append(j.text)\n",
    "\n",
    "            for k in i.find_all('a','IRpwTa'):\n",
    "                product.append(k.text)\n",
    "\n",
    "            for l in i.find_all('div','_30jeq3'):\n",
    "                price.append(l.text)\n",
    "\n",
    "        for i in bs.find_all('div','_25b18c')[:40]:\n",
    "            if i.find('div','_3Ay6Sb') is not None:\n",
    "                discount.append(i.text[-7:])\n",
    "            else:\n",
    "                discount.append('-')\n",
    "\n",
    "        print('Data extracted for page:',page,'\\n')\n",
    "\n",
    "        if page == end_page:\n",
    "            break\n",
    "        else:    \n",
    "            nxt.click()\n",
    "            print('loading.............','\\n')\n",
    "            time.sleep(5)\n",
    "            page += 1\n",
    "\n",
    "    glasses_df = pd.DataFrame({'Brand': brand,\n",
    "                              'Product_description': product,\n",
    "                              'Price': price,\n",
    "                              'Discount':discount})   \n",
    "    return glasses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading............. \n",
      "\n",
      "Data extracted for page: 1 \n",
      "\n",
      "loading............. \n",
      "\n",
      "Data extracted for page: 2 \n",
      "\n",
      "loading............. \n",
      "\n",
      "Data extracted for page: 3 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hipe</td>\n",
       "      <td>Mirrored, UV Protection, Gradient Round Sungla...</td>\n",
       "      <td>₹163</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Royal Son</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (49)</td>\n",
       "      <td>₹699</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDA COLLECTION</td>\n",
       "      <td>Gradient, Mirrored, UV Protection Round, Round...</td>\n",
       "      <td>₹210</td>\n",
       "      <td>83% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDA COLLECTION</td>\n",
       "      <td>Gradient, Mirrored, UV Protection Round, Round...</td>\n",
       "      <td>₹210</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Phenomenal</td>\n",
       "      <td>UV Protection, Mirrored Retro Square Sunglasse...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>MAXX</td>\n",
       "      <td>UV Protection Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹144</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Shahs collections</td>\n",
       "      <td>Polarized Round Sunglasses (50)</td>\n",
       "      <td>₹99</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Scaglia</td>\n",
       "      <td>UV Protection Round Sunglasses (58)</td>\n",
       "      <td>₹165</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>I Flash</td>\n",
       "      <td>UV Protection, Gradient Round Sunglasses (48)</td>\n",
       "      <td>₹130</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection, Night Vision, Riding Glasses Sp...</td>\n",
       "      <td>₹314</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Brand                                Product_description  \\\n",
       "0                 hipe  Mirrored, UV Protection, Gradient Round Sungla...   \n",
       "1            Royal Son         UV Protection Retro Square Sunglasses (49)   \n",
       "2       FDA COLLECTION  Gradient, Mirrored, UV Protection Round, Round...   \n",
       "3       FDA COLLECTION  Gradient, Mirrored, UV Protection Round, Round...   \n",
       "4           Phenomenal  UV Protection, Mirrored Retro Square Sunglasse...   \n",
       "..                 ...                                                ...   \n",
       "115               MAXX       UV Protection Aviator Sunglasses (Free Size)   \n",
       "116  Shahs collections                    Polarized Round Sunglasses (50)   \n",
       "117            Scaglia                UV Protection Round Sunglasses (58)   \n",
       "118            I Flash      UV Protection, Gradient Round Sunglasses (48)   \n",
       "119              NuVew  UV Protection, Night Vision, Riding Glasses Sp...   \n",
       "\n",
       "    Price Discount  \n",
       "0    ₹163  88% off  \n",
       "1    ₹699  65% off  \n",
       "2    ₹210  83% off  \n",
       "3    ₹210  85% off  \n",
       "4    ₹399  80% off  \n",
       "..    ...      ...  \n",
       "115  ₹144  84% off  \n",
       "116   ₹99  80% off  \n",
       "117  ₹165  79% off  \n",
       "118  ₹130  86% off  \n",
       "119  ₹314  60% off  \n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using user-defined function 'flipkart_products' for scraping sunglasses data\n",
    "flipkart_products(product = 'sunglasses' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extracted for page: 1\n",
      "Data extracted for page: 2\n",
      "Data extracted for page: 3\n",
      "Data extracted for page: 4\n",
      "Data extracted for page: 5\n",
      "Data extracted for page: 6\n",
      "Data extracted for page: 7\n",
      "Data extracted for page: 8\n",
      "Data extracted for page: 9\n",
      "Data extracted for page: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>Full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.I’m am ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money❤️❤️Its awesome mobile phone in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3</td>\n",
       "      <td>Nice</td>\n",
       "      <td>Iphone 11 black 64gb is really a cool phone 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>3</td>\n",
       "      <td>Nice</td>\n",
       "      <td>Although it’s an iPhone, it doesn’t give anyth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Just wow!</td>\n",
       "      <td>Apple i Phone is the best phone available in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>use outside gives a outstanding experience ......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4</td>\n",
       "      <td>Delightful</td>\n",
       "      <td>Just the display held it from being a 5star ph...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating              Review  \\\n",
       "0       5    Perfect product!   \n",
       "1       5       Great product   \n",
       "2       5    Perfect product!   \n",
       "3       5  Highly recommended   \n",
       "4       5    Perfect product!   \n",
       "..    ...                 ...   \n",
       "95      3                Nice   \n",
       "96      3                Nice   \n",
       "97      5           Just wow!   \n",
       "98      5           Brilliant   \n",
       "99      4          Delightful   \n",
       "\n",
       "                                          Full_review  \n",
       "0   Amazing phone with great cameras and better ba...  \n",
       "1   Amazing Powerful and Durable Gadget.I’m am ver...  \n",
       "2   It’s a must buy who is looking for an upgrade ...  \n",
       "3   iphone 11 is a very good phone to buy only if ...  \n",
       "4   Value for money❤️❤️Its awesome mobile phone in...  \n",
       "..                                                ...  \n",
       "95  Iphone 11 black 64gb is really a cool phone 1....  \n",
       "96  Although it’s an iPhone, it doesn’t give anyth...  \n",
       "97  Apple i Phone is the best phone available in t...  \n",
       "98  use outside gives a outstanding experience ......  \n",
       "99  Just the display held it from being a 5star ph...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing web driver and webpage\n",
    "driver  = webdriver.Chrome( r'C:\\Users\\91743\\chromedriver.exe')\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace')\n",
    "time.sleep(5)\n",
    "driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[10]/div/div/div[5]/div/a').click()\n",
    "time.sleep(5)\n",
    "driver.find_element_by_xpath(\"//nav[@class = 'yFHi8N']/a[1]\").click()\n",
    "time.sleep(5)\n",
    "review_summary = []\n",
    "rating = []\n",
    "full_review = []\n",
    "\n",
    "# loop for extracting product reviews and ratings for each page till page 10\n",
    "page = 1\n",
    "end_page = 10\n",
    "while page <= end_page:\n",
    "    bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    review = bs.find('div','_1YokD2 _3Mn1Gg col-9-12')\n",
    "    print('Data extracted for page:',page)\n",
    "    for i in review:\n",
    "        for j in i.find_all('p','_2-N8zT'):\n",
    "            review_summary.append(j.text)\n",
    "        for k in i.find_all('div','t-ZTKy'):\n",
    "                 full_review.append(k.text)\n",
    "\n",
    "    for i in driver.find_elements_by_class_name('_27M-vq'):\n",
    "             rating.append(i.text[0])\n",
    "\n",
    "    if page == 1:\n",
    "        driver.find_element_by_xpath(\"//nav[@class = 'yFHi8N']/a[11]\").click()\n",
    "        \n",
    "    elif  1 < page < end_page :\n",
    "         driver.find_element_by_xpath(\"//nav[@class = 'yFHi8N']/a[12]\").click()\n",
    "            \n",
    "    else:\n",
    "        break\n",
    "    time.sleep(5)\n",
    "    page+= 1\n",
    "            \n",
    "review_df = pd.DataFrame({'Rating':rating,\n",
    "                          'Review': review_summary,\n",
    "                          'Full_review':full_review})\n",
    "review_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q8: Scrape data of  sneakers from flipkart.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading............. \n",
      "\n",
      "Data extracted for page: 1 \n",
      "\n",
      "loading............. \n",
      "\n",
      "Data extracted for page: 2 \n",
      "\n",
      "loading............. \n",
      "\n",
      "Data extracted for page: 3 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WHITE WALKERS</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DIGITRENDZZ</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Combo Pack of 4 Casual Sneakers With Sneakers ...</td>\n",
       "      <td>₹579</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>171 Smart Tan Lace-Ups Casuals for Men Sneaker...</td>\n",
       "      <td>₹273</td>\n",
       "      <td>45% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deny Brown</td>\n",
       "      <td>445 Sports Shoes Sneakers For Men</td>\n",
       "      <td>₹369</td>\n",
       "      <td>26% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Combo Pack of 5 Casual Sneakers With Sneakers ...</td>\n",
       "      <td>₹705</td>\n",
       "      <td>71% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Sparx</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹570</td>\n",
       "      <td>12% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>TR</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Essence</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹2,919</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                Product_description   Price  \\\n",
       "0    WHITE WALKERS                                   Sneakers For Men    ₹499   \n",
       "1      DIGITRENDZZ                                   Sneakers For Men    ₹399   \n",
       "2           Chevit  Combo Pack of 4 Casual Sneakers With Sneakers ...    ₹579   \n",
       "3           Chevit  171 Smart Tan Lace-Ups Casuals for Men Sneaker...    ₹273   \n",
       "4       Deny Brown                  445 Sports Shoes Sneakers For Men    ₹369   \n",
       "..             ...                                                ...     ...   \n",
       "115         Chevit  Combo Pack of 5 Casual Sneakers With Sneakers ...    ₹705   \n",
       "116          Sparx                                   Sneakers For Men    ₹570   \n",
       "117             TR                                   Sneakers For Men    ₹399   \n",
       "118        Essence                                   Sneakers For Men    ₹499   \n",
       "119           Puma                                   Sneakers For Men  ₹2,919   \n",
       "\n",
       "    Discount  \n",
       "0    50% off  \n",
       "1    60% off  \n",
       "2    70% off  \n",
       "3    45% off  \n",
       "4    26% off  \n",
       "..       ...  \n",
       "115  71% off  \n",
       "116  12% off  \n",
       "117  60% off  \n",
       "118  50% off  \n",
       "119  55% off  \n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using user-defined function 'flipkart_products' for scraping sneakers data\n",
    "flipkart_products(product = 'sneakers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q9: Write a program to scrape 100 shoes data from myntra.com "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men FREE RN 5.0 Running Shoes</td>\n",
       "      <td>7995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men AIR ZOOM Running Shoes</td>\n",
       "      <td>11995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>PEGASUS FLYEASE Running Shoes</td>\n",
       "      <td>9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Lqdcell Training or Gym</td>\n",
       "      <td>7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Women Solid Sneakers</td>\n",
       "      <td>8499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Solid Leather Formal Slip-Ons</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Vanilla Moon</td>\n",
       "      <td>Women Perforations Flat Boots</td>\n",
       "      <td>9990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Clarks</td>\n",
       "      <td>Men Solid Leather Sneakers</td>\n",
       "      <td>7649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Ruosh</td>\n",
       "      <td>Men Solid Leather Formal Monks</td>\n",
       "      <td>8990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>FILA</td>\n",
       "      <td>Women Sneakers</td>\n",
       "      <td>8999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand                Product_description   Price\n",
       "0           Nike      Men FREE RN 5.0 Running Shoes    7995\n",
       "1           Nike         Men AIR ZOOM Running Shoes   11995\n",
       "2           Nike      PEGASUS FLYEASE Running Shoes    9995\n",
       "3           Puma        Men Lqdcell Training or Gym    7999\n",
       "4      Cole Haan               Women Solid Sneakers    8499\n",
       "..           ...                                ...     ...\n",
       "95  Hush Puppies  Men Solid Leather Formal Slip-Ons    9999\n",
       "96  Vanilla Moon      Women Perforations Flat Boots    9990\n",
       "97        Clarks         Men Solid Leather Sneakers    7649\n",
       "98         Ruosh     Men Solid Leather Formal Monks    8990\n",
       "99          FILA                     Women Sneakers    8999\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing web driver and webpage\n",
    "driver  = webdriver.Chrome( r'C:\\Users\\91743\\chromedriver.exe')\n",
    "driver.get('https://www.myntra.com/shoes')\n",
    "time.sleep(3)\n",
    "# selecting color and price range\n",
    "driver.find_element_by_xpath('//*[@id=\"mountRoot\"]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div').click()\n",
    "time.sleep(3)\n",
    "driver.find_element_by_xpath('//*[@id=\"mountRoot\"]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div').click()\n",
    "time.sleep(3)\n",
    "\n",
    "# loop for extracting shoe data for each page till page 2 \n",
    "brand = []\n",
    "product = []\n",
    "price = []\n",
    "page = 1\n",
    "end_page = 2\n",
    "while page <= end_page:\n",
    "    bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    shoe_info = bs.find_all('div', attrs ={'class':'product-productMetaInfo'})\n",
    "    \n",
    "    for i in shoe_info:\n",
    "        brand.append(i.find('h3','product-brand').text)\n",
    "        product.append(i.find('h4','product-product').text)\n",
    "        price.append(i.find('div','product-price').text.split('Rs.')[1])\n",
    "\n",
    "    if page == end_page:\n",
    "        break\n",
    "    else:\n",
    "        driver.find_element_by_xpath('//ul[@class = \"pagination-container\"]/li[12]/a').click()\n",
    "        time.sleep(5)\n",
    "        page += 1\n",
    "shoe_df = pd.DataFrame({'Brand': brand,\n",
    "                       'Product_description': product,\n",
    "                       'Price': price})\n",
    "shoe_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q10:Write a program to srape first 10 laptop data from amazon.in for processor type i7 and i9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asus ROG Strix G15 Core i7 10th Gen - (8 GB/51...</td>\n",
       "      <td>₹84,990.00</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP Pavilion x360 Core i7 8th Gen 14-inch Touch...</td>\n",
       "      <td>₹82,990.00</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Renewed) Dell Inspiron 3567 Laptop Core i3-7t...</td>\n",
       "      <td>₹29,990.00</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS ZenBook 14 (2020) Intel Core i7-1165G7 11...</td>\n",
       "      <td>₹95,840.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS ZenBook Flip S OLED, Intel Evo Core i7-11...</td>\n",
       "      <td>₹1,49,990.00</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS TUF Gaming F15 Laptop 15.6\" FHD Intel Cor...</td>\n",
       "      <td>₹73,990.00</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lenovo ThinkPad E14 Intel Core i7 10th Gen14-i...</td>\n",
       "      <td>₹84,990.00</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...</td>\n",
       "      <td>₹2,69,294.00</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS VivoBook Ultra 15 (2020) Intel Core i7-11...</td>\n",
       "      <td>₹69,990.00</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Renewed) Lenovo ThinkPad High Performance 12....</td>\n",
       "      <td>₹36,699.00</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Product         Price Rating\n",
       "0  Asus ROG Strix G15 Core i7 10th Gen - (8 GB/51...    ₹84,990.00      -\n",
       "1  HP Pavilion x360 Core i7 8th Gen 14-inch Touch...    ₹82,990.00    4.1\n",
       "2  (Renewed) Dell Inspiron 3567 Laptop Core i3-7t...    ₹29,990.00      -\n",
       "3  ASUS ZenBook 14 (2020) Intel Core i7-1165G7 11...    ₹95,840.00      5\n",
       "4  ASUS ZenBook Flip S OLED, Intel Evo Core i7-11...  ₹1,49,990.00      -\n",
       "5  ASUS TUF Gaming F15 Laptop 15.6\" FHD Intel Cor...    ₹73,990.00    3.5\n",
       "6  Lenovo ThinkPad E14 Intel Core i7 10th Gen14-i...    ₹84,990.00      -\n",
       "7  ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...  ₹2,69,294.00    2.8\n",
       "8  ASUS VivoBook Ultra 15 (2020) Intel Core i7-11...    ₹69,990.00      -\n",
       "9  (Renewed) Lenovo ThinkPad High Performance 12....    ₹36,699.00    3.4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing web driver and webpage\n",
    "driver  = webdriver.Chrome( r'C:\\Users\\91743\\chromedriver.exe')\n",
    "driver.get('https://www.amazon.in/')\n",
    "time.sleep(3)\n",
    "# search for product\n",
    "driver.find_element_by_id('twotabsearchtextbox').send_keys('Laptop')\n",
    "driver.find_element_by_xpath('//div[@class = \"nav-search-submit nav-sprite\"]/span/input').click()\n",
    "time.sleep(3)\n",
    "\n",
    "# check whether 'NoSuchElementException' occurs while selecting processor type and to handle exception if it exists.\n",
    "try:\n",
    "    driver.find_element_by_xpath('//li[@id =\"p_n_feature_thirteen_browse-bin/16757432031\"]/span/a/div/label').click()\n",
    "    time.sleep(3)\n",
    "    driver.find_element_by_xpath('//li[@id =\"p_n_feature_thirteen_browse-bin/12598163031\"]/span/a/div/label').click()\n",
    "except NoSuchElementException:\n",
    "    driver.find_element_by_xpath('//li[@id =\"p_n_feature_thirteen_browse-bin/16757432031\"]/span/a/div/label').click()\n",
    "time.sleep(3)\n",
    "\n",
    "# loop for extracting first 10 laptop data \n",
    "product = []\n",
    "price = []\n",
    "rating = []\n",
    "bs= BeautifulSoup(driver.page_source, 'html.parser')\n",
    "product_url = bs.find_all('a', attrs ={'class':'a-link-normal a-text-normal'})\n",
    "for i in product_url[:10]:\n",
    "    driver.get('https://www.amazon.in/'+i['href'])\n",
    "    bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    product.append(bs.find('span','a-size-large product-title-word-break').text.replace('\\n',''))\n",
    "    \n",
    "    try:\n",
    "        price.append(bs.find('span','a-size-medium a-color-price priceBlockBuyingPriceString').text.replace('\\xa0',''))\n",
    "    except AttributeError:\n",
    "        price.append(bs.find('span','a-size-medium a-color-price priceBlockDealPriceString').text.replace('\\xa0',''))\n",
    "        \n",
    "    try:\n",
    "        rating.append(bs.find('span','a-size-medium a-color-base').text[:-9])\n",
    "    except AttributeError:\n",
    "        rating.append('-')\n",
    "laptop_df = pd.DataFrame({'Product':product,\n",
    "                          'Price': price,\n",
    "                          'Rating': rating})\n",
    "laptop_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
